{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fa8ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "import translators as ts\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#round 1\n",
    "#balance label\n",
    "\n",
    "#round2\n",
    "\n",
    "#random swap\n",
    "def random_swap(sentence, swap_num = 2, nlp = spacy.load('en_core_web_sm')):\n",
    "    tokens = nlp(sentence)\n",
    "    str_list = [str(tok) for tok in tokens]\n",
    "    for i in range (1,swap_num):\n",
    "        a,b = random.randint(0,len(str_list)-1),random.randint(0,len(str_list)-1)\n",
    "        temp = str_list[a]\n",
    "        str_list[a] = str_list[b]\n",
    "        str_list[b] = temp\n",
    "    aug_sentence = ' '.join(str_list)    \n",
    "    \n",
    "    return aug_sentence\n",
    "\n",
    "#random delete\n",
    "def random_delete(sentence, delete_num = 1, nlp = spacy.load('en_core_web_sm')):\n",
    "    tokens = nlp(sentence)\n",
    "    str_list = [str(tok) for tok in tokens]\n",
    "    if len(str_list) <= 5:\n",
    "        return ' '.join(str_list)\n",
    "    if delete_num < 0:\n",
    "        delete_num = 0\n",
    "    for i in range(delete_num):\n",
    "        a = random.randint(0,len(str_list)-1)\n",
    "        str_list.remove(str_list[a])\n",
    "    aug_sentence = ' '.join(str_list)\n",
    "    return aug_sentence\n",
    "\n",
    "#translate and translate\n",
    "def double_translate(sentence,lang = 'zh-TW'):\n",
    "    #https://www.loc.gov/standards/iso639-2/php/code_list.php\n",
    "    first_trans = ts.google(sentence, from_language='en', to_language= lang)\n",
    "    return ts.google(first_trans, from_language=lang ,to_language='en')\n",
    "    \n",
    "def label_count(data):\n",
    "    labeldict = {}\n",
    "    df = pd.read_csv(data,sep=',')\n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        emotion = row['Emotion']\n",
    "        if emotion in labeldict:\n",
    "            labeldict[emotion] += 1\n",
    "        else:\n",
    "            labeldict[emotion] = 1\n",
    "\n",
    "    print(labeldict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a21bd99",
   "metadata": {},
   "source": [
    "'neutral': 5960, 'surprise': 1490, 'fear': 338, 'sadness': 876, 'joy': 2312, 'disgust': 364, 'anger': 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8b2a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 5960, 'surprise': 1490, 'joy': 2312, 'sadness': 876, 'fear': 676, 'disgust': 728, 'anger': 1500}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "predict = []\n",
    "labeldict = {}\n",
    "\n",
    "data = \"trainset_AUGr1.csv\"\n",
    "label_count(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b561d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 12520, 'surprise': 3190, 'fear': 1122, 'sadness': 1897, 'joy': 4838, 'disgust': 1154, 'anger': 3208}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndf.drop(df[(df.Emotion != 'fear')& (df.Emotion != 'disgust')].index, inplace=True)\\n\\nnlp = spacy.load('en_core_web_sm')\\n\\nfor index,row in df.iterrows():\\n    delnum = random.randint(1,3)\\n    swap = random.randint(1,5)\\n    new_sentence = double_translate(row['Utterance'])\\n    new_sentence = random_delete(new_sentence,swap,nlp)\\n    new_sentence = random_swap(new_sentence,delnum,nlp)\\n    row['Utterance'] = new_sentence\\n    \\ndf2 = pd.read_csv(data,sep=',')\\ndf3 = pd.concat([df,df2])\\ndf3 = df3.sample(frac=1)\\ndf3.to_csv('merged_aug_temp.csv',index = False)\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#round 1\n",
    "#先做一次train 一次val，之後再合起來\n",
    "\n",
    "data = \"merged.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[(df.Emotion != 'fear')& (df.Emotion != 'disgust')].index, inplace=True)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(1,5)\n",
    "    new_sentence = double_translate(row['Utterance'])\n",
    "    new_sentence = random_delete(new_sentence,swap,nlp)\n",
    "    new_sentence = random_swap(new_sentence,delnum,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "    \n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sample(frac=1)\n",
    "df3.to_csv('merged_ay.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e192af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2280it [1:46:28,  2.80s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labeldict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-227a3e8bdc26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trainset_AUGr1p5.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mlabel_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trainset_AUGr1p5.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-30d4692fc557>\u001b[0m in \u001b[0;36mlabel_count\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0memotion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Emotion'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0memotion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeldict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mlabeldict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memotion\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labeldict' is not defined"
     ]
    }
   ],
   "source": [
    "#round1.5\n",
    "from tqdm import tqdm\n",
    "data = \"trainset_AUGr1.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[(df.Emotion != 'fear')& (df.Emotion != 'disgust')&(df.Emotion !='sadness')].index, inplace=True)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(1,5)\n",
    "    new_sentence = random_delete(row['Utterance'],delnum,nlp)\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    new_sentence = double_translate(new_sentence,lang = 'ko')#korean\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "    \n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sample(frac=1)\n",
    "df3.to_csv('trainset_AUGr1p5.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "296474cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joy': 2312, 'anger': 1500, 'neutral': 5960, 'sadness': 1752, 'fear': 1352, 'surprise': 1490, 'disgust': 1456}\n"
     ]
    }
   ],
   "source": [
    "label_count('trainset_AUGr1p5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab564f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9862it [9:05:21,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'disgust': 2912, 'anger': 3000, 'joy': 4624, 'surprise': 2980, 'fear': 2704, 'neutral': 5960, 'sadness': 3504}\n"
     ]
    }
   ],
   "source": [
    "#round 1.75\n",
    "data = \"trainset_AUGr1p5.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[df.Emotion == 'neutral'].index, inplace=True)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(2,5)\n",
    "    new_sentence = random_delete(row['Utterance'],delnum,nlp)\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    new_sentence = double_translate(new_sentence,lang = 'tr')#turkish\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "    \n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sample(frac=1)\n",
    "df3.to_csv('trainset_AUGr1p75.csv',index = False)\n",
    "label_count('trainset_AUGr1p75.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e481b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round 2\n",
    "data = \"trainset_Augr1.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[df.Utterance.apply(lambda x: len(x.split(' ')) < 6)].index,inplace = True)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(3,7)\n",
    "    new_sentence = random_delete(new_sentence,swap,nlp)\n",
    "    new_sentence = random_swap(new_sentence,delnum,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "\n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = [df,df2]\n",
    "result = pd.concat(df3)\n",
    "result.to_csv('train_Aug_round2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "159d589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13542\n",
      "1547\n",
      "15089\n"
     ]
    }
   ],
   "source": [
    "#merge train valid\n",
    "\n",
    "data = \"trainset_AUGr1.csv\"\n",
    "df = pd.read_csv(data)\n",
    "data2 = \"valid_augset.csv\"\n",
    "df2 = pd.read_csv(data2)\n",
    "print(len(df))\n",
    "print(len(df2))\n",
    "df3 = [df,df2]\n",
    "df3 = pd.concat(df3)\n",
    "print(len(df3))\n",
    "df3.to_csv('merged_Aug_r1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63138442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Dialogue_ID</th>\n",
       "      <th>Utterance_ID</th>\n",
       "      <th>Old_Dialogue_ID</th>\n",
       "      <th>Old_Utterance_ID</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>also I was the point person on my company’s tr...</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:16,059</td>\n",
       "      <td>00:16:21,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You must’ve had your hands full.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:21,940</td>\n",
       "      <td>00:16:23,442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That I did. That I did.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:23,442</td>\n",
       "      <td>00:16:26,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So let’s talk a little bit about your duties.</td>\n",
       "      <td>The Interviewer</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:26,820</td>\n",
       "      <td>00:16:29,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My duties?  All right.</td>\n",
       "      <td>Chandler</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>00:16:34,452</td>\n",
       "      <td>00:16:40,917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>When I first moved to the city, I went out a c...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>disgust</td>\n",
       "      <td>2159</td>\n",
       "      <td>2</td>\n",
       "      <td>1038</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:35,744</td>\n",
       "      <td>00:00:44,334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>It made me nuts.</td>\n",
       "      <td>Joey</td>\n",
       "      <td>disgust</td>\n",
       "      <td>2159</td>\n",
       "      <td>3</td>\n",
       "      <td>1038</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:45,462</td>\n",
       "      <td>00:00:46,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>You guys are messing with me, right?</td>\n",
       "      <td>Joey</td>\n",
       "      <td>surprise</td>\n",
       "      <td>2159</td>\n",
       "      <td>4</td>\n",
       "      <td>1038</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:01:00,518</td>\n",
       "      <td>00:01:03,520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>Yeah.</td>\n",
       "      <td>All</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2159</td>\n",
       "      <td>5</td>\n",
       "      <td>1038</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:01:05,398</td>\n",
       "      <td>00:01:07,274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>That was a good one. For a second there, I was...</td>\n",
       "      <td>Joey</td>\n",
       "      <td>joy</td>\n",
       "      <td>2159</td>\n",
       "      <td>6</td>\n",
       "      <td>1038</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>00:01:08,401</td>\n",
       "      <td>00:01:12,071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25680 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Utterance          Speaker  \\\n",
       "0      also I was the point person on my company’s tr...         Chandler   \n",
       "1                       You must’ve had your hands full.  The Interviewer   \n",
       "2                                That I did. That I did.         Chandler   \n",
       "3          So let’s talk a little bit about your duties.  The Interviewer   \n",
       "4                                 My duties?  All right.         Chandler   \n",
       "...                                                  ...              ...   \n",
       "12835  When I first moved to the city, I went out a c...             Joey   \n",
       "12836                                   It made me nuts.             Joey   \n",
       "12837               You guys are messing with me, right?             Joey   \n",
       "12838                                              Yeah.              All   \n",
       "12839  That was a good one. For a second there, I was...             Joey   \n",
       "\n",
       "        Emotion  Dialogue_ID  Utterance_ID  Old_Dialogue_ID  Old_Utterance_ID  \\\n",
       "0       neutral            0             0                0                 0   \n",
       "1       neutral            0             1                0                 1   \n",
       "2       neutral            0             2                0                 2   \n",
       "3       neutral            0             3                0                 3   \n",
       "4      surprise            0             4                0                 4   \n",
       "...         ...          ...           ...              ...               ...   \n",
       "12835   disgust         2159             2             1038                11   \n",
       "12836   disgust         2159             3             1038                12   \n",
       "12837  surprise         2159             4             1038                15   \n",
       "12838   neutral         2159             5             1038                16   \n",
       "12839       joy         2159             6             1038                17   \n",
       "\n",
       "       Season  Episode     StartTime       EndTime  \n",
       "0           8       21  00:16:16,059  00:16:21,731  \n",
       "1           8       21  00:16:21,940  00:16:23,442  \n",
       "2           8       21  00:16:23,442  00:16:26,389  \n",
       "3           8       21  00:16:26,820  00:16:29,572  \n",
       "4           8       21  00:16:34,452  00:16:40,917  \n",
       "...       ...      ...           ...           ...  \n",
       "12835       2        3  00:00:35,744  00:00:44,334  \n",
       "12836       2        3  00:00:45,462  00:00:46,587  \n",
       "12837       2        3  00:01:00,518  00:01:03,520  \n",
       "12838       2        3  00:01:05,398  00:01:07,274  \n",
       "12839       2        3  00:01:08,401  00:01:12,071  \n",
       "\n",
       "[25680 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e67c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [16:12,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral': 600, 'sadness': 290, 'disgust': 124, 'surprise': 210, 'joy': 214, 'anger': 208, 'fear': 216}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1262it [1:09:54,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 416, 'disgust': 248, 'surprise': 420, 'joy': 428, 'neutral': 600, 'sadness': 580, 'fear': 432}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data = \"validset_AUGr1.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[(df.Emotion != 'fear')& (df.Emotion != 'disgust')&(df.Emotion !='sadness')].index, inplace=True)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(1,5)\n",
    "    new_sentence = random_delete(row['Utterance'],delnum,nlp)\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    new_sentence = double_translate(new_sentence,lang = 'ko')#korean\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "    \n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sample(frac=1)\n",
    "df3.to_csv('validset_AUGr1p5.csv',index = False)\n",
    "label_count('validset_AUGr1p5.csv')\n",
    "\n",
    "#round 1.75\n",
    "data = \"validset_AUGr1p5.csv\"\n",
    "df = pd.read_csv(data,sep=',')\n",
    "df.drop(df[df.Emotion == 'neutral'].index, inplace=True)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for index,row in tqdm(df.iterrows()):\n",
    "    delnum = random.randint(1,3)\n",
    "    swap = random.randint(2,5)\n",
    "    new_sentence = random_delete(row['Utterance'],delnum,nlp)\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    new_sentence = double_translate(new_sentence,lang = 'tr')#turkish\n",
    "    new_sentence = random_swap(new_sentence,swap,nlp)\n",
    "    row['Utterance'] = new_sentence\n",
    "    \n",
    "df2 = pd.read_csv(data,sep=',')\n",
    "df3 = pd.concat([df,df2])\n",
    "df3 = df3.sample(frac=1)\n",
    "df3.to_csv('validset_AUGr1p75.csv',index = False)\n",
    "label_count('validset_AUGr1p75.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f12bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25684\n",
      "3124\n",
      "28808\n"
     ]
    }
   ],
   "source": [
    "data = \"trainset_AUGr1p75.csv\"\n",
    "df = pd.read_csv(data)\n",
    "data2 = \"validset_AUGr1p75.csv\"\n",
    "df2 = pd.read_csv(data2)\n",
    "print(len(df))\n",
    "print(len(df2))\n",
    "df3 = [df,df2]\n",
    "df3 = pd.concat(df3)\n",
    "print(len(df3))\n",
    "df3.to_csv('mergedset_Augr1p75.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29377e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
